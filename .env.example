# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=False

# === RESOURCE LIMITING (Prevents system hangs and crashes) ===
# IMPORTANT: Use start_safe.sh instead of 'python main.py' for best resource control
# Number of Uvicorn workers (1 recommended for minimal resource usage)
MAX_WORKERS=1

# Python/NumPy thread limits (CONSERVATIVE: Use 2 for stability)
OMP_NUM_THREADS=2
OPENBLAS_NUM_THREADS=2
MKL_NUM_THREADS=2
VECLIB_MAXIMUM_THREADS=2
NUMEXPR_NUM_THREADS=2
TOKENIZERS_PARALLELISM=false

# LLM API Keys
GEMINI_API_KEY=your_gemini_api_key_here
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEFAULT_LLM_PROVIDER=gemini  # Options: gemini, deepseek

# LLM Configuration
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2048
LLM_TOP_P=0.9

# Vector Database Configuration
VECTOR_DB_TYPE=chromadb  # Options: chromadb, faiss
VECTOR_DB_PATH=./data/vector_db
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
CHUNK_SIZE=500  # Reduced for lower memory usage
CHUNK_OVERLAP=100  # Reduced for lower memory usage
MAX_EMBEDDING_BATCH_SIZE=16  # CONSERVATIVE: Small batches to prevent memory spikes
CHROMADB_MAX_BATCH_SIZE=50  # CONSERVATIVE: Limit ChromaDB batch operations

# Crawler Configuration (CONSERVATIVE SETTINGS)
CRAWLER_CONCURRENT_REQUESTS=1  # ONE page at a time only
CRAWLER_MAX_THREADS=1  # Single thread
CRAWLER_DOWNLOAD_DELAY=2  # 2 second delay between pages
CRAWLER_TIMEOUT=30
CRAWLER_USER_AGENT=Mozilla/5.0 (compatible; WebCrawlerRAG/1.0)
MAX_CRAWL_DEPTH=2  # Only 2 levels deep
RESPECT_ROBOTS_TXT=True
ENABLE_SITEMAP_CRAWLING=True

# PDF Processing
ENABLE_OCR=True
OCR_LANGUAGES=eng+ara+hin+urd  # English, Arabic, Hindi, Urdu
PDF_MAX_PAGES=500

# Scheduling
CRAWL_INTERVAL_HOURS=24
ENABLE_BACKGROUND_CRAWLING=False  # DISABLED by default to prevent automatic resource usage

# Database (SQLite for simplicity, can use PostgreSQL)
DATABASE_URL=sqlite:///./data/crawler_rag.db

# Logging
LOG_LEVEL=INFO
LOG_FILE_PATH=./data/logs/crawler.log
LOG_MAX_SIZE=100MB
LOG_BACKUP_COUNT=10

# RAG Configuration
RAG_CONTEXT_WINDOW=4096
RAG_TOP_K_RESULTS=5
RAG_SIMILARITY_THRESHOLD=0.7
SNIPPET_LENGTH=300

# Rate Limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_PERIOD=60  # seconds

# CSV Configuration
DOMAINS_CSV_PATH=./data/domains.csv
